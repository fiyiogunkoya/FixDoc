# Kubernetes kubectl apply Errors - Comprehensive Test Fixtures
# Real-world kubectl apply failures and validation errors

# ============================================================================
# Test Case 1: Resource Quota Exceeded
# ============================================================================

$ kubectl apply -f deployment.yaml

Error from server (Forbidden): error when creating "deployment.yaml": pods "api-server-7d8f9b6c5-" is forbidden: exceeded quota: compute-resources, requested: requests.cpu=2, used: requests.cpu=7500m, limited: requests.cpu=8

---FIXTURE_SEPARATOR---

# ============================================================================
# Test Case 2: Image Pull Error (Non-existent Image)
# ============================================================================

$ kubectl apply -f deployment.yaml
deployment.apps/backend created

$ kubectl get pods
NAME                       READY   STATUS             RESTARTS   AGE
backend-5d8f9c7b6-x2k9m   0/1     ImagePullBackOff   0          45s

$ kubectl describe pod backend-5d8f9c7b6-x2k9m

Events:
  Type     Reason     Age                From               Message
  ----     ------     ----               ----               -------
  Normal   Scheduled  2m15s              default-scheduler  Successfully assigned prod/backend-5d8f9c7b6-x2k9m to node-1
  Normal   Pulling    58s (x4 over 2m14s) kubelet           Pulling image "myregistry.azurecr.io/backend:v1.2.3-nonexistent"
  Warning  Failed     57s (x4 over 2m13s) kubelet           Failed to pull image "myregistry.azurecr.io/backend:v1.2.3-nonexistent": rpc error: code = NotFound desc = failed to pull and unpack image "myregistry.azurecr.io/backend:v1.2.3-nonexistent": failed to resolve reference "myregistry.azurecr.io/backend:v1.2.3-nonexistent": myregistry.azurecr.io/backend:v1.2.3-nonexistent: not found
  Warning  Failed     57s (x4 over 2m13s) kubelet           Error: ErrImagePull
  Normal   BackOff    30s (x6 over 2m12s) kubelet           Back-off pulling image "myregistry.azurecr.io/backend:v1.2.3-nonexistent"
  Warning  Failed     30s (x6 over 2m12s) kubelet           Error: ImagePullBackOff

---FIXTURE_SEPARATOR---

# ============================================================================
# Test Case 3: Invalid YAML Syntax
# ============================================================================

$ kubectl apply -f broken-deployment.yaml

error: error parsing broken-deployment.yaml: error converting YAML to JSON: yaml: line 15: did not find expected key

---FIXTURE_SEPARATOR---

# ============================================================================
# Test Case 4: CrashLoopBackOff
# ============================================================================

$ kubectl apply -f deployment.yaml
deployment.apps/worker created

$ kubectl get pods
NAME                      READY   STATUS             RESTARTS      AGE
worker-6b8f7c9d5-p3k8n   0/1     CrashLoopBackOff   5 (32s ago)   4m12s

$ kubectl describe pod worker-6b8f7c9d5-p3k8n

Events:
  Type     Reason     Age                    From               Message
  ----     ------     ----                   ----               -------
  Normal   Scheduled  4m30s                  default-scheduler  Successfully assigned prod/worker-6b8f7c9d5-p3k8n to node-2
  Normal   Pulled     3m22s (x5 over 4m28s)  kubelet            Container image "myregistry.azurecr.io/worker:v2.1.0" already present on machine
  Normal   Created    3m22s (x5 over 4m28s)  kubelet            Created container worker
  Normal   Started    3m21s (x5 over 4m27s)  kubelet            Started container worker
  Warning  BackOff    2m54s (x9 over 4m25s)  kubelet            Back-off restarting failed container worker in pod worker-6b8f7c9d5-p3k8n_prod(a1b2c3d4-5678-90ab-cdef-123456789012)

$ kubectl logs worker-6b8f7c9d5-p3k8n

panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x4a8f32]

goroutine 1 [running]:
main.main()
        /app/main.go:45 +0x112

---FIXTURE_SEPARATOR---

# ============================================================================
# Test Case 5: OOMKilled
# ============================================================================

$ kubectl get pods
NAME                        READY   STATUS      RESTARTS      AGE
data-processor-abc123-xyz   0/1     OOMKilled   3 (1m ago)    5m

$ kubectl describe pod data-processor-abc123-xyz

Containers:
  processor:
    State:          Terminated
      Reason:       OOMKilled
      Exit Code:    137
      Started:      Mon, 15 Jan 2025 10:30:00 +0000
      Finished:     Mon, 15 Jan 2025 10:32:45 +0000
    Last State:     Terminated
      Reason:       OOMKilled
      Exit Code:    137
    Ready:          False
    Restart Count:  3
    Limits:
      memory:  512Mi
    Requests:
      memory:  256Mi

Events:
  Type     Reason     Age                  From               Message
  ----     ------     ----                 ----               -------
  Warning  OOMKilling 45s (x3 over 4m12s)  kubelet            Memory cgroup out of memory: Killed process 12345 (processor) total-vm:1245632kB, anon-rss:524456kB, file-rss:0kB, shmem-rss:0kB

---FIXTURE_SEPARATOR---

# ============================================================================
# Test Case 6: PersistentVolumeClaim Pending
# ============================================================================

$ kubectl apply -f statefulset.yaml
statefulset.apps/database created

$ kubectl get pvc
NAME                    STATUS    VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE
data-database-0         Pending                                      premium-ssd    2m

$ kubectl describe pvc data-database-0

Events:
  Type     Reason              Age                From                         Message
  ----     ------              ----               ----                         -------
  Warning  ProvisioningFailed  15s (x8 over 2m)   persistentvolume-controller  storageclass.storage.k8s.io "premium-ssd" not found

---FIXTURE_SEPARATOR---

# ============================================================================
# Test Case 7: Service Account Not Found
# ============================================================================

$ kubectl apply -f deployment.yaml

Error from server (Forbidden): error when creating "deployment.yaml": pods "api-7d8f9b6c5-" is forbidden: error looking up service account prod/nonexistent-sa: serviceaccount "nonexistent-sa" not found

---FIXTURE_SEPARATOR---

# ============================================================================
# Test Case 8: ConfigMap/Secret Not Found
# ============================================================================

$ kubectl apply -f deployment.yaml
deployment.apps/api-server created

$ kubectl get pods
NAME                          READY   STATUS                       RESTARTS   AGE
api-server-5d8f9c7b6-m2n3o   0/1     CreateContainerConfigError   0          30s

$ kubectl describe pod api-server-5d8f9c7b6-m2n3o

Events:
  Type     Reason     Age               From               Message
  ----     ------     ----              ----               -------
  Normal   Scheduled  35s               default-scheduler  Successfully assigned prod/api-server-5d8f9c7b6-m2n3o to node-1
  Warning  Failed     5s (x4 over 33s)  kubelet            Error: configmap "app-config" not found

---FIXTURE_SEPARATOR---

# ============================================================================
# Test Case 9: Node Affinity - No Matching Nodes
# ============================================================================

$ kubectl apply -f deployment.yaml
deployment.apps/gpu-workload created

$ kubectl get pods
NAME                           READY   STATUS    RESTARTS   AGE
gpu-workload-7c9d8e5f4-k2l3m   0/1     Pending   0          5m

$ kubectl describe pod gpu-workload-7c9d8e5f4-k2l3m

Events:
  Type     Reason            Age                  From               Message
  ----     ------            ----                 ----               -------
  Warning  FailedScheduling  2m15s (x3 over 5m)   default-scheduler  0/5 nodes are available: 5 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.

---FIXTURE_SEPARATOR---

# ============================================================================
# Test Case 10: Readiness Probe Failing
# ============================================================================

$ kubectl apply -f deployment.yaml
deployment.apps/web-app created

$ kubectl get pods
NAME                       READY   STATUS    RESTARTS   AGE
web-app-6b7c8d9e5-x1y2z   0/1     Running   0          3m

$ kubectl describe pod web-app-6b7c8d9e5-x1y2z

Events:
  Type     Reason     Age                  From               Message
  ----     ------     ----                 ----               -------
  Normal   Scheduled  3m15s                default-scheduler  Successfully assigned prod/web-app-6b7c8d9e5-x1y2z to node-3
  Normal   Pulled     3m14s                kubelet            Container image "myregistry.azurecr.io/web-app:v1.0.0" already present on machine
  Normal   Created    3m14s                kubelet            Created container web-app
  Normal   Started    3m13s                kubelet            Started container web-app
  Warning  Unhealthy  10s (x18 over 2m50s) kubelet            Readiness probe failed: HTTP probe failed with statuscode: 503

---FIXTURE_SEPARATOR---

# ============================================================================
# Test Case 11: Namespace Terminating - Cannot Create Resources
# ============================================================================

$ kubectl apply -f deployment.yaml -n legacy-app

Error from server (Forbidden): error when creating "deployment.yaml": deployments.apps "api-server" is forbidden: unable to create new content in namespace legacy-app because it is being terminated

---FIXTURE_SEPARATOR---

# ============================================================================
# Test Case 12: Resource Version Conflict
# ============================================================================

$ kubectl apply -f deployment.yaml

Error from server (Conflict): error when applying patch:
{"metadata":{"annotations":{"kubectl.kubernetes.io/last-applied-configuration":"{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\"..."}}}
to:
Resource: "apps/v1, Resource=deployments", GroupVersionKind: "apps/v1, Kind=Deployment"
Name: "api-server", Namespace: "prod"
for: "deployment.yaml": Operation cannot be fulfilled on deployments.apps "api-server": the object has been modified; please apply your changes to the latest version and try again

---FIXTURE_SEPARATOR---

# ============================================================================
# Test Case 13: Invalid Resource Specification
# ============================================================================

$ kubectl apply -f deployment.yaml

Error from server (Invalid): error when creating "deployment.yaml": Deployment.apps "api-server" is invalid: spec.template.spec.containers[0].resources.requests: Invalid value: "5000m": must be less than or equal to cpu limit of 2
